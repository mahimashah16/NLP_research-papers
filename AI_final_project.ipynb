{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahimashah16/NLP_research-papers/blob/main/AI_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2fxMcGs2FKT"
      },
      "outputs": [],
      "source": [
        "!brew install portaudio\n",
        "!pip install pyaudio\n",
        "!pip3 install SpeechRecognition pydub\n",
        "!pip install punctuator\n",
        "!pip install transformers==2.2.2#for abstractive\n",
        "!pip install bert-extractive-summarizer #for extractive\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9WVQ2JV2FKW"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "# from pyhub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import os\n",
        "import nltk\n",
        "from transformers import pipeline\n",
        "#from summarizer import Summarizer\n",
        "from nltk import sent_tokenize\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NRQB8os2FKW"
      },
      "outputs": [],
      "source": [
        "r = sr.Recognizer()\n",
        "with sr.Microphone() as source:\n",
        "    audio_data = r.record(source, duration=60)\n",
        "    print(\"Recognizing......\")\n",
        "    DOCUMENT = r.recognize_google(audio_data)\n",
        "    print(DOCUMENT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq_oRksB2FKX"
      },
      "outputs": [],
      "source": [
        "from punctuator import Punctuator\n",
        "p = Punctuator('/Users/deekshitakamble/Downloads/INTERSPEECH-T-BRNN.pcl')\n",
        "DOCUMENT = p.punctuate(DOCUMENT)\n",
        "print(p.punctuate(DOCUMENT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bu21pNS2FKX"
      },
      "outputs": [],
      "source": [
        "x=r'/Users/deekshitakamble/Documents/COMP520/audio.txt'\n",
        "\n",
        "if os.path.exists(x):\n",
        "    if os.path.isfile(x):\n",
        "        print(\"file is existed\")\n",
        "        with open('audio.txt', 'w') as f:\n",
        "            f.write(DOCUMENT)\n",
        "            f.close()\n",
        "    elif os.path.isdir(x):\n",
        "        print(\"directory is existed\")\n",
        "\n",
        "else:\n",
        "    print(\"file is not existed and creating a new file\")\n",
        "    with open('audio.txt', 'w') as f:\n",
        "        f.write(DOCUMENT)\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CrF4OD02FKX"
      },
      "outputs": [],
      "source": [
        "def read_text(path_to_file):\n",
        "  f = open(path_to_file, 'r', encoding='utf8')\n",
        "  text = f.read()\n",
        "  f.close()\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiBk_c4t2FKY"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.strip()\n",
        "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
        "    text = re.sub('\\.+', '.', text)\n",
        "    text = text.replace('«', '\"').replace('»', '\"')\n",
        "    text = re.sub('[\\.\\?\\!\\;]\"', '\"', text)\n",
        "    text = re.sub('[\\.\\?\\!]\\;\"', ';', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    text = re.sub('\\t+', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def smart_tokenization(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    res = []\n",
        "    cur_text = ''\n",
        "    for sent in sentences:\n",
        "        #2000 - max count of symbols for abstractive model\n",
        "        if len(cur_text + sent) > 2000:\n",
        "            res.append(cur_text)\n",
        "            cur_text = sent\n",
        "        else:\n",
        "            cur_text += sent\n",
        "    if cur_text != '':\n",
        "      res.append(cur_text)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO9jnA152FKY"
      },
      "outputs": [],
      "source": [
        "class AbstractiveSummarizer():\n",
        "    def __init__(self):\n",
        "        self.model = pipeline('summarization')\n",
        "\n",
        "    def generate_summary(self, text):\n",
        "        text = preprocess_text(text)\n",
        "        parts = smart_tokenization(text)\n",
        "        res = []\n",
        "        for part in parts:\n",
        "            res.append(self.model(part)[0]['summary_text'])\n",
        "        return ' '.join(res)\n",
        "\n",
        "\n",
        "class ExtractiveSummarizer():\n",
        "    def __init__(self):\n",
        "        self.model = Summarizer()\n",
        "\n",
        "    def generate_summary(self, text):\n",
        "        text = preprocess_text(text)\n",
        "        return self.model(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWd_1TKr2FKY"
      },
      "outputs": [],
      "source": [
        "from summarizer import Summarizer\n",
        "summarizer = AbstractiveSummarizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_TO_SUMMARIZE = read_text('/Users/deekshitakamble/Documents/COMP520/audio.txt')\n",
        "summarizer.generate_summary(TEXT_TO_SUMMARIZE) #takes about 40 seconds"
      ],
      "metadata": {
        "id": "drhrl4t02R7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFx3P5Ma2FKZ"
      },
      "outputs": [],
      "source": [
        "from summarizer import Summarizer\n",
        "summarizer = ExtractiveSummarizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_TO_SUMMARIZE = read_text('/Users/deekshitakamble/Documents/COMP520/audio.txt')\n",
        "summarizer.generate_summary(TEXT_TO_SUMMARIZE) #takes about 40 seconds"
      ],
      "metadata": {
        "id": "dEOkd97S2U_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}